DL20

Official leaderboard and additional generated systems (based on GPT).

The paper displays an abridged version of Question with grade threshold 4.


| System | generated? | Question / Qrels-MRR |  |  | Nugget / Qrels -MRR |  |  | Official rank |
| :-- | :-- | :-- | :-- | --- | :-- | :-- | --- | :-- |
| best self rating >= |  | 3 | 4 | 5 | 3 | 4 | 5 |  |
| GPT4-question | \* | 0.827 | 0.747 | 0.658 | 1 | 1 | 0.982 |  |
| GPT3.5-question | \* | 0.812 | 0.743 | 0.65 | 1 | 1 | 0.991 |  |
| pash\_f3 |  | 0.856 | 0.738 | 0.579 | 0.991 | 0.982 | 0.978 | 3 |
| pash\_f2 |  | 0.846 | 0.737 | 0.578 | 0.991 | 0.982 | 0.978 | 5 |
| NLE\_pr2 |  | 0.799 | 0.729 | 0.575 | 0.991 | 0.982 | 0.972 | 16 |
| pash\_f1 |  | 0.837 | 0.728 | 0.569 | 0.991 | 0.982 | 0.978 | 4 |
| pash\_r3 |  | 0.846 | 0.721 | 0.579 | 0.991 | 0.982 | 0.978 | 1 |
| NLE\_pr1 |  | 0.794 | 0.719 | 0.586 | 0.991 | 0.982 | 0.972 | 17 |
| pash\_r2 |  | 0.859 | 0.712 | 0.57 | 0.991 | 0.982 | 0.978 | 2 |
| 2 |  | 0.785 | 0.709 | 0.572 | 0.991 | 0.991 | 0.982 | 25 |
| 1 |  | 0.804 | 0.706 | 0.572 | 0.991 | 0.991 | 0.982 | 18 |
| RMIT-Bart |  | 0.813 | 0.705 | 0.57 | 0.991 | 0.976 | 0.964 | 10 |
| bigIR-T5-BERT-F |  | 0.815 | 0.699 | 0.573 | 0.991 | 0.991 | 0.982 | 26 |
| pash\_r1 |  | 0.824 | 0.698 | 0.541 | 0.982 | 0.96 | 0.948 | 11 |
| NLE\_pr3 |  | 0.805 | 0.695 | 0.563 | 1 | 0.991 | 0.982 | 12 |
| p\_bm25rm3\_duo |  | 0.814 | 0.693 | 0.559 | 0.991 | 0.978 | 0.966 | 8 |
| p\_d2q\_rm3\_duo |  | 0.814 | 0.693 | 0.559 | 0.991 | 0.978 | 0.966 | 7 |
| p\_d2q\_bm25\_duo |  | 0.814 | 0.693 | 0.559 | 0.991 | 0.978 | 0.966 | 6 |
| pinganNLP2 |  | 0.82 | 0.69 | 0.539 | 0.982 | 0.968 | 0.958 | 13 |
| pinganNLP1 |  | 0.82 | 0.69 | 0.538 | 0.982 | 0.968 | 0.958 | 15 |
| bigIR-BERT-R |  | 0.802 | 0.688 | 0.56 | 0.991 | 0.978 | 0.969 | 19 |
| CoRT-bm25 |  | 0.765 | 0.683 | 0.532 | 0.991 | 0.978 | 0.978 | 38 |
| CoRT-electra |  | 0.764 | 0.681 | 0.554 | 1 | 0.991 | 0.969 | 9 |
| CoRT-standalone |  | 0.762 | 0.68 | 0.53 | 0.991 | 0.978 | 0.978 | 39 |
| relemb\_mlm\_0\_2 |  | 0.739 | 0.676 | 0.521 | 0.991 | 0.991 | 0.982 | 31 |
| pinganNLP3 |  | 0.804 | 0.674 | 0.536 | 0.991 | 0.968 | 0.958 | 14 |
| fr\_pass\_roberta |  | 0.765 | 0.674 | 0.57 | 0.991 | 0.982 | 0.972 | 20 |
| bcai\_bertl\_pass |  | 0.8 | 0.672 | 0.564 | 0.991 | 0.991 | 0.982 | 23 |
| bigIR-T5-R |  | 0.772 | 0.671 | 0.568 | 0.982 | 0.972 | 0.96 | 24 |
| rr-pass-roberta |  | 0.781 | 0.67 | 0.567 | 0.991 | 0.972 | 0.963 | 22 |
| TUW-TK-Sparse |  | 0.764 | 0.664 | 0.497 | 0.991 | 0.982 | 0.972 | 33 |
| nlm-ens-bst-3 |  | 0.745 | 0.664 | 0.563 | 0.991 | 0.969 | 0.969 | 29 |
| nlm-ens-bst-2 |  | 0.758 | 0.661 | 0.548 | 0.991 | 0.96 | 0.96 | 28 |
| bert\_6 |  | 0.763 | 0.659 | 0.567 | 0.991 | 0.976 | 0.976 | 37 |
| bigIR-DCT-T5-F |  | 0.744 | 0.649 | 0.542 | 0.991 | 0.982 | 0.969 | 21 |
| nlm-bert-rr |  | 0.757 | 0.644 | 0.529 | 0.982 | 0.963 | 0.954 | 30 |
| nlm-prfun-bert |  | 0.72 | 0.635 | 0.506 | 0.982 | 0.958 | 0.958 | 32 |
| bigIR-T5xp-T5-F |  | 0.723 | 0.63 | 0.531 | 0.991 | 0.982 | 0.969 | 27 |
| GPT3.5-wikipedia | \* | 0.723 | 0.627 | 0.497 | 1 | 1 | 1 |  |
| TUW-TK-2Layer |  | 0.779 | 0.622 | 0.511 | 0.991 | 0.968 | 0.956 | 34 |
| p\_d2q\_bm25rm3 |  | 0.73 | 0.591 | 0.459 | 0.991 | 0.991 | 0.974 | 36 |
| p\_d2q\_bm25 |  | 0.705 | 0.589 | 0.456 | 0.982 | 0.958 | 0.949 | 35 |
| terrier-InL2 |  | 0.675 | 0.541 | 0.442 | 1 | 0.975 | 0.963 | 44 |
| GPT4-wikipedia | \* | 0.663 | 0.528 | 0.418 | 1 | 1 | 0.991 |  |
| terrier-BM25 |  | 0.672 | 0.528 | 0.41 | 0.991 | 0.977 | 0.965 | 45 |
| bcai\_class\_pass |  | 0.65 | 0.513 | 0.39 | 0.991 | 0.986 | 0.949 | 41 |
| bm25\_bert\_token |  | 0.636 | 0.513 | 0.42 | 0.991 | 0.985 | 0.976 | 51 |
| indri-fdm |  | 0.653 | 0.51 | 0.433 | 0.991 | 0.986 | 0.986 | 43 |
| TF\_IDF\_d\_2\_t\_50 |  | 0.608 | 0.507 | 0.349 | 0.975 | 0.958 | 0.914 | 53 |
| GPT3.5-web | \* | 0.597 | 0.506 | 0.466 | 0.932 | 0.932 | 0.932 |  |
| p\_bm25rm3 |  | 0.603 | 0.504 | 0.378 | 0.97 | 0.956 | 0.943 | 49 |
| indri-sdm |  | 0.626 | 0.498 | 0.425 | 0.955 | 0.951 | 0.951 | 48 |
| bl\_bcai\_mdl1\_vt |  | 0.639 | 0.493 | 0.356 | 0.982 | 0.966 | 0.957 | 40 |
| p\_bm25 |  | 0.617 | 0.482 | 0.397 | 0.972 | 0.965 | 0.961 | 50 |
| indri-lmds |  | 0.614 | 0.477 | 0.417 | 1 | 0.985 | 0.975 | 47 |
| GPT4-web | \* | 0.63 | 0.473 | 0.361 | 0.907 | 0.889 | 0.889 |  |
| terrier-DPH |  | 0.619 | 0.454 | 0.395 | 1 | 0.986 | 0.986 | 52 |
| DLH\_d\_5\_t\_25 |  | 0.559 | 0.451 | 0.354 | 0.971 | 0.956 | 0.944 | 46 |
| bl\_bcai\_mdl1\_vs |  | 0.618 | 0.433 | 0.358 | 0.991 | 0.986 | 0.958 | 42 |
| small\_1k |  | 0.399 | 0.34 | 0.21 | 0.714 | 0.699 | 0.681 | 54 |
| DoRA\_Large\_1k |  | 0.353 | 0.319 | 0.195 | 0.681 | 0.673 | 0.657 | 56 |
| med\_1k |  | 0.363 | 0.313 | 0.183 | 0.701 | 0.693 | 0.664 | 55 |
| DoRA\_Small |  | 0.234 | 0.155 | 0.128 | 0.743 | 0.678 | 0.664 | 57 |
| DoRA\_Med |  | 0.189 | 0.13 | 0.103 | 0.734 | 0.682 | 0.642 | 58 |
| DoRA\_Large |  | 0.186 | 0.113 | 0.104 | 0.707 | 0.666 | 0.628 | 59 |

